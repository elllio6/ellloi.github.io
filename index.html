<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>FunnyImageAI — Stable (image + voice)</title>

  <!-- TensorFlow.js + MobileNet -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.9.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@2.2.1/dist/mobilenet.min.js"></script>

  <style>
    :root{
      --accent:#0b6df2;
      --muted:#6b7280;
      --bg:#f6f9ff;
      --card:#ffffff;
      --radius:12px;
      --pad:14px;
    }
    html,body{height:100%;margin:0;font-family:Inter,system-ui,-apple-system,"Segoe UI",Roboto,Arial;background:var(--bg);color:#0f172a}
    .wrap{max-width:1100px;margin:20px auto;padding:18px;box-sizing:border-box}
    header{display:flex;justify-content:space-between;align-items:center;margin-bottom:16px;gap:12px}
    h1{margin:0;font-size:1.25rem}
    .subtitle{color:var(--muted);font-size:0.95rem}
    .grid{display:grid;grid-template-columns:1fr 420px;gap:16px}
    @media (max-width:980px){ .grid{grid-template-columns:1fr} }
    .card{background:var(--card);border-radius:var(--radius);padding:var(--pad);box-shadow:0 8px 20px rgba(12,18,36,0.06)}
    .uploader{display:flex;flex-direction:column;align-items:center;justify-content:center;border:2px dashed #e6eefc;border-radius:10px;padding:18px;background:linear-gradient(180deg,#fff,#fbfdff)}
    .hidden{display:none}
    img.preview{max-width:100%;border-radius:8px;margin-top:12px;display:block}
    label{display:block;font-weight:700;margin-bottom:8px}
    input[type="file"], input[type="text"], input[type="number"], select, textarea { width:100%; padding:10px; border-radius:8px; border:1px solid #e6eefc; background:#fff; box-sizing:border-box }
    textarea{min-height:90px; resize:vertical}
    button { display:inline-flex; align-items:center; gap:8px; padding:10px 14px; border-radius:9px; border:0; background:var(--accent); color:#fff; cursor:pointer; font-weight:600 }
    button.ghost { background:transparent; color:var(--accent); border:1px solid var(--accent) }
    button.secondary { background:#6b7280 }
    .small{font-size:0.9rem;color:var(--muted)}
    .pred-list{list-style:none;padding:0;margin:12px 0}
    .pred-list li{padding:8px 6px;border-bottom:1px dashed #f1f5f9}
    .controls{display:flex;gap:8px;flex-wrap:wrap;margin-top:10px}
    .status { font-size:0.95rem; color:var(--muted); margin-left:8px }
    .top-controls { display:flex; gap:8px; align-items:center }
    .clip-item { display:flex; gap:8px; align-items:center; justify-content:space-between; padding:6px 0 }
    footer{margin-top:18px;color:var(--muted);text-align:center}
    .notice { background:#fff7ed; border:1px solid #fee7c6; padding:8px; border-radius:8px; color:#92400e; margin-top:8px }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <div>
        <h1>FunnyImageAI — Stable</h1>
        <div class="subtitle">One image for guessing. Upload a short audio or a video (audio fallback used) for voice matching.</div>
      </div>
      <div class="top-controls">
        <div class="small">Points: <span id="pointsBadge">0</span></div>
        <button id="enableAudioBtn" class="ghost">Enable audio</button>
        <div id="audioStatus" class="status">Audio: not enabled</div>
      </div>
    </header>

    <div class="grid">
      <!-- MAIN COLUMN -->
      <div>
        <div class="card" id="imageCard">
          <label>Single image (guess target)</label>
          <div class="uploader" id="imageUploader" title="Click choose image">
            <input id="imageInput" type="file" accept="image/*" />
            <button id="pickImageBtn" class="ghost">Choose image</button>
            <div class="small" style="margin-top:8px">Drop or choose an image to classify.</div>
            <img id="imagePreview" class="preview hidden" alt="preview">
          </div>

          <div id="modelStatus" class="small" style="margin-top:12px">Loading model...</div>

          <div id="predictionsArea" class="hidden">
            <label style="margin-top:12px">AI guesses</label>
            <ul id="predList" class="pred-list"></ul>

            <div class="controls">
              <button id="speakBtn" class="ghost">Speak top guess</button>
              <button id="correctBtn">AI correct</button>
              <button id="incorrectBtn" class="secondary">AI incorrect (save)</button>
            </div>

            <div id="labelSaveArea" class="hidden" style="margin-top:10px">
              <input id="correctLabelInput" placeholder="Correct label (exact)">
              <div class="controls" style="margin-top:8px">
                <button id="saveLabelBtn">Save labeled image</button>
                <button id="cancelSaveBtn" class="ghost">Cancel</button>
              </div>
            </div>

            <hr style="margin:12px 0">

            <div style="display:flex;align-items:center;gap:10px;flex-wrap:wrap">
              <button id="startLoopBtn">Start auto-guesses</button>
              <button id="stopLoopBtn" class="ghost hidden">Stop</button>
              <div class="small">Delay</div>
              <input id="minDelay" type="number" min="1" value="2" style="width:70px">
              <div class="small">to</div>
              <input id="maxDelay" type="number" min="1" value="5" style="width:70px">
              <div id="loopStatus" class="status">Stopped</div>
            </div>
          </div>
        </div>

        <div class="card" style="margin-top:14px">
          <label>Saved clips</label>
          <div id="clipContainer" class="small">
            <!-- clip list appended here -->
          </div>
          <div class="small" style="margin-top:8px">Recorded clips / uploaded audio appear above. Use in templates like <code>{clip:name}</code>.</div>
        </div>
      </div>

      <!-- SIDE PANEL -->
      <div>
        <div class="card">
          <label>Voice source</label>
          <div style="display:flex;flex-direction:column;gap:8px">
            <div>
              <div class="small">Upload audio (recommended) — MP3/WAV/AAC</div>
              <input id="audioInput" type="file" accept="audio/*">
            </div>
            <div>
              <div class="small">Or upload a video and try built-in extraction (may be limited on some Safari versions)</div>
              <input id="videoInput" type="file" accept="video/*">
              <video id="videoPlayer" controls class="hidden" style="width:100%;margin-top:8px"></video>
            </div>

            <div>
              <div style="display:flex;gap:8px">
                <input id="segStart" type="number" min="0" step="0.1" placeholder="start (s)">
                <input id="segEnd" type="number" min="0" step="0.1" placeholder="end (s)">
              </div>
              <div class="controls" style="margin-top:8px">
                <button id="extractClipBtn">Extract & match</button>
                <button id="previewSegBtn" class="ghost">Preview segment</button>
              </div>
              <div id="extractStatus" class="small" style="margin-top:8px"></div>
            </div>
          </div>
        </div>

        <div class="card" style="margin-top:14px">
          <div style="display:flex;justify-content:space-between;align-items:center">
            <strong>Voice Maker</strong>
            <span class="small muted">Templates use <code>{label}</code> and <code>{clip:name}</code></span>
          </div>

          <label style="margin-top:10px">Choose script</label>
          <select id="vmScriptList"></select>

          <label style="margin-top:8px">Script name</label>
          <input id="vmName">

          <label style="margin-top:8px">Templates (one per line)</label>
          <textarea id="vmTemplates"></textarea>

          <label style="margin-top:8px">Suggested pitch</label>
          <input id="vmPitch" type="number" step="0.1" min="0" max="2" value="1.0">

          <label style="margin-top:8px">Suggested rate</label>
          <input id="vmRate" type="number" step="0.1" min="0.5" max="2" value="1.0">

          <div style="display:flex;gap:8px;margin-top:10px">
            <button id="vmSave">Save script</button>
            <button id="vmNew" class="ghost">New</button>
            <button id="vmDelete" class="secondary">Delete</button>
          </div>
        </div>
      </div>
    </div>

    <footer>
      <div class="small muted">Improved stability: the app avoids blocking the UI and provides a safe audio-upload fallback for Safari. Clips & data are stored locally in your browser.</div>
    </footer>
  </div>

<script>
/*
  Stable, Safari-friendly implementation:
  - Avoids captureStream/MediaRecorder path that caused freezes.
  - Primary voice input: audio upload (recommended). If a video is uploaded, we try to decode audio from the file's bytes (best-effort).
  - decodeAudioData used carefully with async flows and cancellation tokens to avoid freezing the UI.
  - Better UI states and clear error handling.
  - Robust TTS: user must click "Enable audio" once (Safari gesture); wait for voices to load.
  - Auto-guess loop that cycles through shuffled candidates and waits between 2-5s (configurable).
*/

// ---------- Storage helpers ----------
const SCRIPTS_KEY = 'funnyai_scripts_stable_v1';
const CLIPS_KEY = 'funnyai_clips_stable_v1';
const DATASET_KEY = 'funnyai_dataset_stable_v1';
const POINTS_KEY = 'funnyai_points_stable_v1';

function defaultScripts(){
  return {
    "Shy": { templates: ["Um... I think this might be {label}."], pitch:1.0, rate:1.0 },
    "Sarcastic": { templates: ["Oh sure, definitely {label}... or not."], pitch:1.0, rate:0.95 },
    "Confident": { templates: ["I'm pretty sure this is {label}."], pitch:1.0, rate:1.1 }
  };
}
function loadScripts(){ try { const raw = localStorage.getItem(SCRIPTS_KEY); return raw ? JSON.parse(raw) : defaultScripts(); } catch(e){ return defaultScripts(); } }
function saveScripts(s){ localStorage.setItem(SCRIPTS_KEY, JSON.stringify(s)); }
function loadClips(){ try { return JSON.parse(localStorage.getItem(CLIPS_KEY) || '{}'); } catch(e){ return {}; } }
function saveClips(c){ localStorage.setItem(CLIPS_KEY, JSON.stringify(c)); }
function loadDataset(){ try { return JSON.parse(localStorage.getItem(DATASET_KEY) || '{}'); } catch(e){ return {}; } }
function saveDataset(d){ localStorage.setItem(DATASET_KEY, JSON.stringify(d)); }
function loadPoints(){ return parseInt(localStorage.getItem(POINTS_KEY) || '0', 10); }
function savePoints(n){ localStorage.setItem(POINTS_KEY, String(n)); updatePointsBadge(); }
function updatePointsBadge(){ document.getElementById('pointsBadge').textContent = loadPoints(); }

// ---------- Model ----------
let net = null;
async function loadModel(){
  document.getElementById('modelStatus').textContent = 'Loading MobileNet model...';
  try {
    net = await mobilenet.load({version:2, alpha:1.0});
    document.getElementById('modelStatus').textContent = 'Model loaded.';
  } catch(e){
    document.getElementById('modelStatus').textContent = 'Model failed to load: ' + (e.message || e);
    console.error('MobileNet load error', e);
  }
}

// ---------- Voice / TTS (Safari-friendly) ----------
let AVAILABLE_VOICES = [];
let VOICES_READY = false;
let audioEnabled = false; // user must press Enable audio

function ensureVoicesLoaded(timeoutMs = 1500){
  return new Promise((resolve) => {
    const v = window.speechSynthesis.getVoices();
    if(v && v.length){ AVAILABLE_VOICES = v; VOICES_READY = true; return resolve(v); }
    const onvoices = () => { const vv = window.speechSynthesis.getVoices(); AVAILABLE_VOICES = vv; VOICES_READY = true; window.speechSynthesis.removeEventListener('voiceschanged', onvoices); resolve(vv); };
    window.speechSynthesis.addEventListener('voiceschanged', onvoices);
    setTimeout(()=> { const vv = window.speechSynthesis.getVoices() || []; AVAILABLE_VOICES = vv; VOICES_READY = AVAILABLE_VOICES.length>0; window.speechSynthesis.removeEventListener('voiceschanged', onvoices); resolve(AVAILABLE_VOICES); }, timeoutMs);
  });
}

function pickVoiceIndex(preferredIndex = null){
  if(preferredIndex !== null && !isNaN(preferredIndex) && AVAILABLE_VOICES[preferredIndex]) return preferredIndex;
  for(let i=0;i<AVAILABLE_VOICES.length;i++){
    const v = AVAILABLE_VOICES[i];
    if(/en/i.test(v.lang) || /english/i.test(v.name)) return i;
  }
  return AVAILABLE_VOICES.length ? 0 : null;
}

async function speakText(text, rate=1.0, pitch=1.0, preferredVoiceIndex=null){
  if(!audioEnabled){ console.warn('Audio not enabled.'); return; }
  if(!('speechSynthesis' in window)){ console.warn('No speechSynthesis'); return; }
  await ensureVoicesLoaded();
  return new Promise((resolve) => {
    try {
      const u = new SpeechSynthesisUtterance(String(text));
      u.rate = Number.isFinite(rate) ? rate : 1.0;
      u.pitch = Number.isFinite(pitch) ? pitch : 1.0;
      const idx = pickVoiceIndex(preferredVoiceIndex);
      if(idx !== null && AVAILABLE_VOICES[idx]) u.voice = AVAILABLE_VOICES[idx];
      u.onend = () => resolve();
      u.onerror = () => resolve();
      window.speechSynthesis.speak(u);
    } catch(err){
      console.warn('speakText error', err); resolve();
    }
  });
}

// ---------- Playback helpers ----------
function playClipDataUrl(dataUrl){
  return new Promise(resolve => {
    const a = new Audio(dataUrl);
    a.onended = () => resolve();
    a.onerror = () => resolve();
    a.play().catch(()=>resolve());
  });
}

function buildSequenceFromTemplate(template, label){
  const seq = []; const rx = /\{clip:([^}]+)\}/g;
  let lastIndex = 0, m;
  while((m = rx.exec(template)) !== null){
    const before = template.slice(lastIndex, m.index);
    if(before.trim()) seq.push({type:'tts', text: before.replace(/\{label\}/g, label)});
    seq.push({type:'clip', clip: m[1].trim()});
    lastIndex = m.index + m[0].length;
  }
  const tail = template.slice(lastIndex);
  if(tail.trim()) seq.push({type:'tts', text: tail.replace(/\{label\}/g, label)});
  return seq;
}
async function playSequence(seq, rate=1.0, pitch=1.0){
  for(const item of seq){
    if(item.type === 'clip'){
      const clips = loadClips();
      const dataUrl = clips[item.clip];
      if(dataUrl) await playClipDataUrl(dataUrl);
      else await new Promise(r=>setTimeout(r,120));
    } else if(item.type === 'tts'){
      const t = (item.text||'').trim();
      if(t) await speakText(t, rate, pitch);
      else await new Promise(r=>setTimeout(r,80));
    }
  }
}

// ---------- Pitch estimator (fast heuristic) ----------
async function estimatePitchFromAudioBuffer(audioBuffer){
  try {
    const fs = audioBuffer.sampleRate;
    const channel = audioBuffer.getChannelData(0);
    const N = Math.min(channel.length, fs); // first second
    const buf = channel.subarray(0, N);
    let bestOffset = -1, bestVal = 0;
    for(let offset=20; offset<800; offset++){
      let s = 0;
      for(let i=0;i<N-offset;i++) s += Math.abs(buf[i] - buf[i+offset]);
      const val = 1/(1+s);
      if(val > bestVal){ bestVal = val; bestOffset = offset; }
    }
    if(bestOffset <= 0) return null;
    return fs / bestOffset;
  } catch(e){ console.warn('pitch estimate failed', e); return null; }
}

// ---------- File decoding helpers (video/audio) ----------
let extractionSession = 0; // simple cancellation token for async extraction

// Try to decode the audio track from an uploaded file's bytes.
// Many browsers can decode audio from container files (mp4, webm) via decodeAudioData.
// This is best-effort and won't freeze the UI because we run async and check session token.
async function tryDecodeAudioFromFile(file){
  const session = ++extractionSession;
  const arr = await file.arrayBuffer();
  if(session !== extractionSession) throw new Error('cancelled');
  // Use AudioContext.decodeAudioData (async)
  const actx = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(1, 44100, 44100);
  try {
    const audioBuffer = await new Promise((res, rej) => {
      actx.decodeAudioData(arr.slice(0), decoded => res(decoded), err => rej(err));
    });
    if(session !== extractionSession) throw new Error('cancelled');
    return audioBuffer;
  } catch(err) {
    // decodeAudioData failed (likely unsupported container). Return null to fallback to audio upload path.
    console.warn('decodeAudioData failed', err);
    return null;
  }
}

// Build dataURL from a Blob asynchronously
function blobToDataURL(blob){
  return new Promise((res, rej) => {
    const fr = new FileReader();
    fr.onload = () => res(fr.result);
    fr.onerror = rej;
    fr.readAsDataURL(blob);
  });
}

// ---------- Small "funny badness" ----------
function applySmallBadness(preds){
  const commons = ["banana","chair","shoe","cat","dog","tree","car","clock","bottle","cup","box"];
  let labels = preds.map(p => [p[0], p[1]]);
  if(Math.random() < 0.35){
    const fake = commons[Math.floor(Math.random()*commons.length)];
    labels[0] = [fake, 0.10 + Math.random()*0.08];
    for(let i=1;i<labels.length;i++) labels[i][1] = Math.max(0.01, labels[i][1]*0.6);
  } else {
    labels = labels.map(([lbl,score]) => [lbl, Math.max(0.05, score*0.5)]);
  }
  if(Math.random() < 0.25 && labels.length>2){
    const t = labels[1]; labels[1] = labels[2]; labels[2] = t;
  }
  return labels;
}

// ---------- Guess loop ----------
let guessLoopRunning = false;
let guessCandidates = [];
let guessIndex = 0;
let lastGuessed = null;
function shuffleArray(a){ for(let i=a.length-1;i>0;i--){ const j=Math.floor(Math.random()*(i+1)); [a[i],a[j]]=[a[j],a[i]] } return a; }
function buildGuessCandidates(preds){
  const commons = ["banana","chair","shoe","cat","dog","tree","car","clock","bottle","cup","box"];
  const labels = preds.map(p=>p[0]);
  const out = labels.slice();
  commons.forEach(c => { if(!out.includes(c) && out.length < Math.max(6, labels.length+3)) out.push(c); });
  return shuffleArray(out);
}
function sleep(ms){ return new Promise(r => setTimeout(r, ms)); }

async function startGuessLoop(){
  if(guessLoopRunning) return;
  if(!lastPredictions || lastPredictions.length === 0){ alert('Upload an image first.'); return; }
  if(!audioEnabled){ alert('Tap "Enable audio" to allow speech (Safari requires a gesture).'); return; }
  guessCandidates = buildGuessCandidates(lastPredictions);
  guessIndex = 0;
  guessLoopRunning = true;
  document.getElementById('startLoopBtn').classList.add('hidden');
  document.getElementById('stopLoopBtn').classList.remove('hidden');
  document.getElementById('loopStatus').textContent = 'Running';
  while(guessLoopRunning){
    if(guessIndex >= guessCandidates.length){ guessCandidates = shuffleArray(guessCandidates.slice()); guessIndex = 0; }
    let label = guessCandidates[guessIndex++];
    if(label === lastGuessed && guessCandidates.length>1) label = guessCandidates[guessIndex++ % guessCandidates.length];
    lastGuessed = label;
    const scriptName = document.getElementById('vmScriptList').value;
    const script = loadScripts()[scriptName] || null;
    const tpl = script ? script.templates[Math.floor(Math.random()*script.templates.length)] : 'I think this is {label}.';
    const seq = buildSequenceFromTemplate(tpl, label);
    const pitch = script ? (script.pitch||1.0) : 1.0;
    const rate = script ? (script.rate||1.0) : 1.0;
    await playSequence(seq, rate, pitch);
    if(!guessLoopRunning) break;
    let minD = parseFloat(document.getElementById('minDelay').value) || 2;
    let maxD = parseFloat(document.getElementById('maxDelay').value) || 5;
    if(maxD < minD) { const t=minD; minD=maxD; maxD=t; }
    const delay = minD + Math.random()*(maxD - minD);
    const start = Date.now();
    while(guessLoopRunning && Date.now() - start < delay*1000){ await sleep(200); }
  }
  guessLoopRunning = false;
  document.getElementById('startLoopBtn').classList.remove('hidden');
  document.getElementById('stopLoopBtn').classList.add('hidden');
  document.getElementById('loopStatus').textContent = 'Stopped';
}

function stopGuessLoop(){ guessLoopRunning = false; }

// ---------- UI glue ----------
let currentImageEl = null;
let lastPredictions = [];

function renderPredictions(preds){
  const ul = document.getElementById('predList'); ul.innerHTML = '';
  preds.forEach((p,i) => {
    const li = document.createElement('li');
    li.innerHTML = `<strong>${i+1}. ${escapeHtml(p[0])}</strong> — ${(p[1]*100).toFixed(1)}%`;
    ul.appendChild(li);
  });
}
function escapeHtml(s){ return String(s).replace(/[&<>"']/g, c => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[c])); }

function populateUI(){
  const scripts = loadScripts();
  const sel = document.getElementById('vmScriptList');
  sel.innerHTML = '';
  Object.keys(scripts).sort().forEach(k => { const o = document.createElement('option'); o.value = k; o.textContent = k; sel.appendChild(o); });
  if(sel.options.length) sel.value = sel.options[0].value;
  loadScriptEditor();
  refreshClipUI();
  updatePointsBadge();
}

function loadScriptEditor(){
  const name = document.getElementById('vmScriptList').value;
  const scripts = loadScripts();
  if(!name || !scripts[name]) return;
  const v = scripts[name];
  document.getElementById('vmName').value = name;
  document.getElementById('vmTemplates').value = (v.templates||[]).join('\n');
  document.getElementById('vmPitch').value = v.pitch || 1.0;
  document.getElementById('vmRate').value = v.rate || 1.0;
}

function refreshClipUI(){
  const container = document.getElementById('clipContainer');
  container.innerHTML = '';
  const clips = loadClips();
  const keys = Object.keys(clips).sort();
  if(keys.length === 0){ container.innerHTML = '<div class="small muted">No clips saved yet.</div>'; return; }
  keys.forEach(k => {
    const row = document.createElement('div'); row.className = 'clip-item';
    const left = document.createElement('div'); left.innerHTML = `<strong>${escapeHtml(k)}</strong>`;
    const right = document.createElement('div');
    const play = document.createElement('a'); play.href='#'; play.textContent='Play'; play.addEventListener('click', (e)=>{ e.preventDefault(); new Audio(clips[k]).play();});
    const del = document.createElement('a'); del.href='#'; del.textContent='Delete'; del.style.color='#ef4444'; del.style.marginLeft='10px';
    del.addEventListener('click', (e)=>{ e.preventDefault(); if(!confirm('Delete clip '+k+'?')) return; const c = loadClips(); delete c[k]; saveClips(c); refreshClipUI(); });
    right.appendChild(play); right.appendChild(del);
    row.appendChild(left); row.appendChild(right);
    container.appendChild(row);
  });
}

// ---------- Event wiring ----------
document.addEventListener('DOMContentLoaded', async ()=>{
  if(!localStorage.getItem(SCRIPTS_KEY)) saveScripts(defaultScripts());
  populateUI();
  loadModel();

  // Enable audio button
  document.getElementById('enableAudioBtn').addEventListener('click', async ()=>{
    audioEnabled = true;
    document.getElementById('audioStatus').textContent = 'Audio: enabled';
    await ensureVoicesLoaded(2000);
    try { await speakText('Audio enabled', 1.0, 1.0); } catch(e) { console.warn(e); }
  });

  // IMAGE upload
  document.getElementById('pickImageBtn').addEventListener('click', ()=> document.getElementById('imageInput').click());
  document.getElementById('imageInput').addEventListener('change', async (ev)=>{
    const f = ev.target.files && ev.target.files[0]; if(!f) return;
    try {
      const url = URL.createObjectURL(f);
      const img = new Image();
      img.src = url;
      await new Promise((res,rej)=>{ img.onload = res; img.onerror = rej; });
      currentImageEl = img;
      const ip = document.getElementById('imagePreview'); ip.src = img.src; ip.classList.remove('hidden');
      if(guessLoopRunning) stopGuessLoop();
      if(!net) await loadModel();
      document.getElementById('modelStatus').textContent = 'Classifying...';
      const raw = await net.classify(img, 5);
      const preds = raw.map(r => [r.className, r.probability]);
      lastPredictions = applySmallBadness(preds);
      renderPredictions(lastPredictions);
      document.getElementById('predictionsArea').classList.remove('hidden');
      document.getElementById('modelStatus').textContent = 'Ready';
    } catch(err){
      console.error('image load/classify', err);
      alert('Image load/classify failed: ' + (err.message || err));
    }
  });

  // SPEAK top button
  document.getElementById('speakBtn').addEventListener('click', async ()=>{
    if(!lastPredictions || !lastPredictions[0]){ alert('No prediction'); return; }
    if(!audioEnabled){ alert('Tap "Enable audio" to allow speech (Safari needs a gesture).'); return; }
    const top = lastPredictions[0][0];
    const scriptName = document.getElementById('vmScriptList').value;
    const script = loadScripts()[scriptName] || null;
    const tpl = script ? script.templates[Math.floor(Math.random()*script.templates.length)] : 'I think this is {label}.';
    const seq = buildSequenceFromTemplate(tpl, top);
    const pitch = script ? (script.pitch||1.0) : 1.0;
    const rate = script ? (script.rate||1.0) : 1.0;
    await playSequence(seq, rate, pitch);
  });

  // Correct / incorrect / save label
  document.getElementById('correctBtn').addEventListener('click', ()=>{ savePoints(loadPoints()+1); alert('Point awarded!'); });
  document.getElementById('incorrectBtn').addEventListener('click', ()=> document.getElementById('labelSaveArea').classList.remove('hidden'));
  document.getElementById('cancelSaveBtn').addEventListener('click', ()=> { document.getElementById('labelSaveArea').classList.add('hidden'); document.getElementById('correctLabelInput').value=''; });
  document.getElementById('saveLabelBtn').addEventListener('click', ()=>{
    const label = (document.getElementById('correctLabelInput').value||'').trim();
    if(!label){ alert('Enter label'); return; }
    if(!currentImageEl){ alert('No image'); return; }
    const canvas = document.createElement('canvas'); canvas.width = currentImageEl.naturalWidth; canvas.height = currentImageEl.naturalHeight;
    const ctx = canvas.getContext('2d'); ctx.drawImage(currentImageEl, 0, 0);
    const dataUrl = canvas.toDataURL('image/jpeg', 0.9);
    const ds = loadDataset(); if(!ds[label]) ds[label]=[]; ds[label].push({data: dataUrl, t: Date.now()}); saveDataset(ds);
    alert('Saved labeled image under: ' + label); document.getElementById('labelSaveArea').classList.add('hidden'); document.getElementById('correctLabelInput').value='';
  });

  // LOOP controls
  document.getElementById('startLoopBtn').addEventListener('click', startGuessLoop);
  document.getElementById('stopLoopBtn').addEventListener('click', stopGuessLoop);

  // AUDIO fallback upload decoding
  document.getElementById('audioInput').addEventListener('change', async (ev)=>{
    const f = ev.target.files && ev.target.files[0]; if(!f) return;
    try {
      document.getElementById('extractStatus').textContent = 'Decoding audio...';
      const actx = new (window.AudioContext || window.webkitAudioContext)();
      const array = await f.arrayBuffer();
      const audioBuffer = await actx.decodeAudioData(array.slice(0));
      // convert file to dataURL for storage/playing
      const dataUrl = await blobToDataURL(new Blob([array], {type: f.type || 'audio/mpeg'}));
      const name = 'audio_' + Date.now();
      const clips = loadClips(); clips[name] = dataUrl; saveClips(clips); refreshClipUI();
      // pitch estimate
      const pitchHz = await estimatePitchFromAudioBuffer(audioBuffer);
      let suggestedPitch = 1.0, suggestedRate = 1.0;
      if(pitchHz && pitchHz>0){
        const p = Math.max(80, Math.min(400, pitchHz));
        const norm = (p - 100) / (300 - 100);
        suggestedPitch = 0.8 + Math.max(0, Math.min(1, norm))*0.7;
        suggestedRate = 0.9 + Math.max(0, Math.min(1, norm))*0.3;
      }
      document.getElementById('vmPitch').value = (Math.round(suggestedPitch*10)/10).toFixed(1);
      document.getElementById('vmRate').value = (Math.round(suggestedRate*10)/10).toFixed(1);
      document.getElementById('extractStatus').textContent = `Saved clip "${name}". Suggested pitch=${document.getElementById('vmPitch').value}, rate=${document.getElementById('vmRate').value}.`;
      // auto-add a VideoVoice script skeleton if missing
      const scripts = loadScripts();
      if(!scripts['VideoVoice']){ scripts['VideoVoice'] = { templates: [`{clip:${name}} I think this is {label}.`], pitch: suggestedPitch, rate: suggestedRate }; saveScripts(scripts); populateUI(); }
    } catch(err){
      console.error('audio decode failed', err); document.getElementById('extractStatus').textContent = 'Audio decode failed'; alert('Audio decode failed: ' + (err.message || err));
    }
  });

  // VIDEO upload: attempt decode from bytes (best-effort)
  document.getElementById('videoInput').addEventListener('change', async (ev)=>{
    const f = ev.target.files && ev.target.files[0]; if(!f) return;
    const videoPlayer = document.getElementById('videoPlayer');
    videoPlayer.src = URL.createObjectURL(f);
    videoPlayer.classList.remove('hidden');
    // try to decode audio track from file bytes (best-effort)
    document.getElementById('extractStatus').textContent = 'Attempting to decode audio from video (best-effort)...';
    extractionSession++;
    const session = extractionSession;
    try {
      const audioBuffer = await tryDecodeAudioFromFile(f);
      if(session !== extractionSession) return; // cancelled
      if(!audioBuffer){
        document.getElementById('extractStatus').textContent = 'Automatic extraction not available for this file — try uploading audio instead.';
        return;
      }
      // Convert audioBuffer to WAV blob for playback and save
      const wavBlob = audioBufferToWavBlob(audioBuffer);
      const dataUrl = await blobToDataURL(wavBlob);
      const name = 'video_audio_' + Date.now();
      const clips = loadClips(); clips[name] = dataUrl; saveClips(clips); refreshClipUI();
      const pitchHz = await estimatePitchFromAudioBuffer(audioBuffer);
      let suggestedPitch = 1.0, suggestedRate = 1.0;
      if(pitchHz && pitchHz>0){
        const p = Math.max(80, Math.min(400, pitchHz));
        const norm = (p - 100) / (300 - 100);
        suggestedPitch = 0.8 + Math.max(0, Math.min(1, norm))*0.7;
        suggestedRate = 0.9 + Math.max(0, Math.min(1, norm))*0.3;
      }
      document.getElementById('vmPitch').value = (Math.round(suggestedPitch*10)/10).toFixed(1);
      document.getElementById('vmRate').value = (Math.round(suggestedRate*10)/10).toFixed(1);
      document.getElementById('extractStatus').textContent = `Saved clip "${name}". Suggested pitch=${document.getElementById('vmPitch').value}, rate=${document.getElementById('vmRate').value}.`;
      const scripts = loadScripts();
      if(!scripts['VideoVoice']){ scripts['VideoVoice'] = { templates: [`{clip:${name}} I think this is {label}.`], pitch: suggestedPitch, rate: suggestedRate }; saveScripts(scripts); populateUI(); }
    } catch(err){
      console.error('video audio extraction error', err);
      document.getElementById('extractStatus').textContent = 'Extraction failed — try uploading audio.';
      alert('Video audio extraction failed: ' + (err.message || err));
    }
  });

  // Preview segment (for video playback)
  document.getElementById('previewSegBtn').addEventListener('click', ()=>{
    const start = parseFloat(document.getElementById('segStart').value || 0);
    const end = parseFloat(document.getElementById('segEnd').value || 0);
    const videoPlayer = document.getElementById('videoPlayer');
    if(!videoPlayer.src){ alert('No video loaded'); return; }
    if(isNaN(start) || isNaN(end) || end <= start){ alert('Invalid times'); return; }
    videoPlayer.currentTime = start;
    videoPlayer.play();
    const stopFn = ()=> { if(videoPlayer.currentTime >= end - 0.05){ videoPlayer.pause(); videoPlayer.removeEventListener('timeupdate', stopFn); } };
    videoPlayer.addEventListener('timeupdate', stopFn);
  });

  // Extract clip (attempt decode from loaded video segment by decoding whole file then slicing)
  document.getElementById('extractClipBtn').addEventListener('click', async ()=>{
    const start = parseFloat(document.getElementById('segStart').value || 0);
    const end = parseFloat(document.getElementById('segEnd').value || 0);
    const videoPlayer = document.getElementById('videoPlayer');
    if(!videoPlayer.src && !document.getElementById('audioInput').files.length){ alert('Load a video or audio first'); return; }
    if(isNaN(start) || isNaN(end) || end <= start){ alert('Invalid start/end'); return; }
    document.getElementById('extractStatus').textContent = 'Extracting...';
    try {
      // If user provided an audio file, prefer that path (we already converted audioInput->clip on change)
      if(document.getElementById('audioInput').files.length){
        document.getElementById('extractStatus').textContent = 'Audio file already uploaded. Use clips in Voice Maker.';
        return;
      }
      // Attempt to decode audio from video file (we already set video.src earlier)
      const input = document.getElementById('videoInput');
      const file = input.files && input.files[0];
      if(!file){ alert('No video file loaded'); return; }
      const audioBuffer = await tryDecodeAudioFromFile(file);
      if(!audioBuffer){ document.getElementById('extractStatus').textContent = 'Could not decode audio from file — try uploading audio directly.'; return; }
      // Slice audioBuffer between start/end seconds
      const sr = audioBuffer.sampleRate;
      const sSample = Math.max(0, Math.floor(start * sr));
      const eSample = Math.min(audioBuffer.length, Math.floor(end * sr));
      const len = Math.max(0, eSample - sSample);
      const newBuf = new (window.AudioContext || window.webkitAudioContext)().createBuffer(audioBuffer.numberOfChannels, len, sr);
      for(let ch=0; ch<audioBuffer.numberOfChannels; ch++){
        const src = audioBuffer.getChannelData(ch).subarray(sSample, eSample);
        newBuf.copyToChannel(src, ch, 0);
      }
      const wavBlob = audioBufferToWavBlob(newBuf);
      const dataUrl = await blobToDataURL(wavBlob);
      const name = 'extracted_' + Date.now();
      const clips = loadClips(); clips[name] = dataUrl; saveClips(clips); refreshClipUI();
      const pitchHz = await estimatePitchFromAudioBuffer(newBuf);
      let suggestedPitch = 1.0, suggestedRate = 1.0;
      if(pitchHz && pitchHz>0){
        const p = Math.max(80, Math.min(400, pitchHz));
        const norm = (p - 100) / (300 - 100);
        suggestedPitch = 0.8 + Math.max(0, Math.min(1, norm))*0.7;
        suggestedRate = 0.9 + Math.max(0, Math.min(1, norm))*0.3;
      }
      document.getElementById('vmPitch').value = (Math.round(suggestedPitch*10)/10).toFixed(1);
      document.getElementById('vmRate').value = (Math.round(suggestedRate*10)/10).toFixed(1);
      document.getElementById('extractStatus').textContent = `Saved clip "${name}". Suggested pitch=${document.getElementById('vmPitch').value}, rate=${document.getElementById('vmRate').value}.`;
      const scripts = loadScripts();
      if(!scripts['VideoVoice']){ scripts['VideoVoice'] = { templates: [`{clip:${name}} I think this is {label}.`], pitch: suggestedPitch, rate: suggestedRate }; saveScripts(scripts); populateUI(); }
    } catch(err){
      console.error('extract failed', err);
      document.getElementById('extractStatus').textContent = 'Extraction failed — use audio upload.';
      alert('Extraction failed: ' + (err.message || err));
    }
  });

  // Voice maker handlers
  document.getElementById('vmScriptList').addEventListener('change', loadScriptEditor);
  document.getElementById('vmSave').addEventListener('click', ()=>{
    const name = (document.getElementById('vmName').value||'').trim();
    if(!name){ alert('Provide name'); return; }
    const templates = (document.getElementById('vmTemplates').value||'').split('\n').map(s=>s.trim()).filter(Boolean);
    if(templates.length===0){ alert('Add at least one template'); return; }
    const pitch = parseFloat(document.getElementById('vmPitch').value) || 1.0;
    const rate = parseFloat(document.getElementById('vmRate').value) || 1.0;
    const scripts = loadScripts(); scripts[name] = { templates, pitch, rate }; saveScripts(scripts); populateUI(); alert('Saved script: ' + name);
  });
  document.getElementById('vmNew').addEventListener('click', ()=>{ document.getElementById('vmName').value='NewScript'; document.getElementById('vmTemplates').value='I think this is {label}.'; document.getElementById('vmPitch').value='1.0'; document.getElementById('vmRate').value='1.0'; });
  document.getElementById('vmDelete').addEventListener('click', ()=>{ const name=(document.getElementById('vmScriptList').value||'').trim(); if(!name) return; if(!confirm('Delete script "'+name+'"?')) return; const scripts = loadScripts(); delete scripts[name]; saveScripts(scripts); populateUI(); alert('Deleted ' + name); });

  populateUI();
});

// ---------- Utility: convert AudioBuffer -> WAV Blob ----------
function audioBufferToWavBlob(buffer){
  // mono or stereo supported
  const numChannels = buffer.numberOfChannels;
  const sampleRate = buffer.sampleRate;
  const length = buffer.length * numChannels * 2 + 44;
  const bufferArray = new ArrayBuffer(length);
  const view = new DataView(bufferArray);
  /* RIFF header */
  function writeString(view, offset, string){
    for(let i=0;i<string.length;i++) view.setUint8(offset + i, string.charCodeAt(i));
  }
  let offset = 0;
  writeString(view, offset, 'RIFF'); offset += 4;
  view.setUint32(offset, 36 + buffer.length * numChannels * 2, true); offset += 4;
  writeString(view, offset, 'WAVE'); offset += 4;
  writeString(view, offset, 'fmt '); offset += 4;
  view.setUint32(offset, 16, true); offset += 4;
  view.setUint16(offset, 1, true); offset += 2; // PCM
  view.setUint16(offset, numChannels, true); offset += 2;
  view.setUint32(offset, sampleRate, true); offset += 4;
  view.setUint32(offset, sampleRate * numChannels * 2, true); offset += 4;
  view.setUint16(offset, numChannels * 2, true); offset += 2;
  view.setUint16(offset, 16, true); offset += 2;
  writeString(view, offset, 'data'); offset += 4;
  view.setUint32(offset, buffer.length * numChannels * 2, true); offset += 4;
  // write interleaved audio data
  const interleaved = new Int16Array(buffer.length * numChannels);
  let idx = 0;
  for(let i=0;i<buffer.length;i++){
    for(let ch=0; ch<numChannels; ch++){
      const sample = Math.max(-1, Math.min(1, buffer.getChannelData(ch)[i]));
      interleaved[idx++] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
    }
  }
  for(let i=0;i<interleaved.length;i++){
    view.setInt16(offset, interleaved[i], true);
    offset += 2;
  }
  return new Blob([view], {type: 'audio/wav'});
}

// ---------- Small helpers used above ----------
function blobToDataURL(blob){ return new Promise((res, rej) => { const fr = new FileReader(); fr.onload = ()=>res(fr.result); fr.onerror = rej; fr.readAsDataURL(blob); }); }

</script>
</body>
</html>
